{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchrec Criteo Terabyte Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. Instantiating Criteo Terabyte dataset\n",
    "2. Defining and applying batch data transformation function\n",
    "3. Defining model\n",
    "4. Training and evaluating model\n",
    "5. Training and evaluating model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torchrec.datasets.criteo import criteo_terabyte\n",
    "\n",
    "torch.set_printoptions(threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating Criteo Terabyte dataset\n",
    "Let's begin by instantiating a datapipe representing the Criteo 1TB Click Logs https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/ dataset (we'll refer to it here as the Criteo Terabyte dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = criteo_terabyte(\n",
    "    (\"/home/jeffhwang/local/datasets/criteo/day_11.tsv\",),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the datapipe returns each sample as a dictionary that maps each default feature name to a typecasted feature value (int for each of the label and 13 integer features, and str for each of the 26 categorical features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'int_0': 0,\n",
       " 'int_1': 0,\n",
       " 'int_2': 0,\n",
       " 'int_3': 0,\n",
       " 'int_4': 0,\n",
       " 'int_5': 1,\n",
       " 'int_6': 0,\n",
       " 'int_7': 124,\n",
       " 'int_8': 0,\n",
       " 'int_9': 1,\n",
       " 'int_10': 0,\n",
       " 'int_11': 1,\n",
       " 'int_12': 0,\n",
       " 'cat_0': '35b29d1c',\n",
       " 'cat_1': '11b5bc17',\n",
       " 'cat_2': '63f76c15',\n",
       " 'cat_3': 'f2463ffb',\n",
       " 'cat_4': '16420cce',\n",
       " 'cat_5': '6fcd6dcb',\n",
       " 'cat_6': '6e1739cb',\n",
       " 'cat_7': '337bf7a5',\n",
       " 'cat_8': '2e4e821f',\n",
       " 'cat_9': '4dc5d654',\n",
       " 'cat_10': '59e53f80',\n",
       " 'cat_11': '12716184',\n",
       " 'cat_12': '00c5ffb7',\n",
       " 'cat_13': 'be4ee537',\n",
       " 'cat_14': 'eb24f585',\n",
       " 'cat_15': '4cdc3efa',\n",
       " 'cat_16': 'd20856aa',\n",
       " 'cat_17': '7232d217',\n",
       " 'cat_18': '9512c20b',\n",
       " 'cat_19': '6c8c076c',\n",
       " 'cat_20': '174c2fe8',\n",
       " 'cat_21': 'b32f71aa',\n",
       " 'cat_22': '59f8acf3',\n",
       " 'cat_23': 'f3a1835d',\n",
       " 'cat_24': '30436bfc',\n",
       " 'cat_25': 'b757e957'}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "bento_obj_id": "140592387409728"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(datapipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adjust the format of each sample via input parameter `row_mapper`. For instance, if we'd prefer to work with lists of feature values, we can define and provide a function that maps a raw split TSV line to a list of typecasted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 124,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " '35b29d1c',\n",
       " '11b5bc17',\n",
       " '63f76c15',\n",
       " 'f2463ffb',\n",
       " '16420cce',\n",
       " '6fcd6dcb',\n",
       " '6e1739cb',\n",
       " '337bf7a5',\n",
       " '2e4e821f',\n",
       " '4dc5d654',\n",
       " '59e53f80',\n",
       " '12716184',\n",
       " '00c5ffb7',\n",
       " 'be4ee537',\n",
       " 'eb24f585',\n",
       " '4cdc3efa',\n",
       " 'd20856aa',\n",
       " '7232d217',\n",
       " '9512c20b',\n",
       " '6c8c076c',\n",
       " '174c2fe8',\n",
       " 'b32f71aa',\n",
       " '59f8acf3',\n",
       " 'f3a1835d',\n",
       " '30436bfc',\n",
       " 'b757e957']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "bento_obj_id": "140590507879232"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchrec.datasets.utils import safe_cast\n",
    "\n",
    "def row_to_list(row):\n",
    "    return [\n",
    "        safe_cast(val, int, 0) for val in row[:14]\n",
    "    ] + [\n",
    "        safe_cast(val, str, \"\") for val in row[14:]\n",
    "    ]\n",
    "\n",
    "list_datapipe = criteo_terabyte(\n",
    "    (\"/home/jeffhwang/local/datasets/criteo/day_11.tsv\",),\n",
    "    row_mapper=row_to_list,\n",
    ")\n",
    "next(iter(list_datapipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, if we'd prefer to operate directly on raw split TSV lines, we can pass `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '',\n",
       " '',\n",
       " '0',\n",
       " '0',\n",
       " '',\n",
       " '1',\n",
       " '0',\n",
       " '124',\n",
       " '0',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '0',\n",
       " '35b29d1c',\n",
       " '11b5bc17',\n",
       " '63f76c15',\n",
       " 'f2463ffb',\n",
       " '16420cce',\n",
       " '6fcd6dcb',\n",
       " '6e1739cb',\n",
       " '337bf7a5',\n",
       " '2e4e821f',\n",
       " '4dc5d654',\n",
       " '59e53f80',\n",
       " '12716184',\n",
       " '00c5ffb7',\n",
       " 'be4ee537',\n",
       " 'eb24f585',\n",
       " '4cdc3efa',\n",
       " 'd20856aa',\n",
       " '7232d217',\n",
       " '9512c20b',\n",
       " '6c8c076c',\n",
       " '174c2fe8',\n",
       " 'b32f71aa',\n",
       " '59f8acf3',\n",
       " 'f3a1835d',\n",
       " '30436bfc',\n",
       " 'b757e957']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "bento_obj_id": "140590530453760"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datapipe = criteo_terabyte(\n",
    "    (\"/home/jeffhwang/local/datasets/criteo/day_11.tsv\",),\n",
    "    row_mapper=None,\n",
    ")\n",
    "next(iter(raw_datapipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we move onto creating train and validation datapipes representing complementary subsets of the dataset and applying a sample limit, batching, and collation to each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrec.datasets.utils import idx_split_train_val\n",
    "\n",
    "datapipe = criteo_terabyte(\n",
    "    (\"/home/jeffhwang/local/datasets/criteo/day_11.tsv\",),\n",
    ")\n",
    "train_datapipe, val_datapipe = idx_split_train_val(datapipe, 0.7)\n",
    "train_datapipe = train_datapipe.limit(int(1e3)).batch(100).collate()\n",
    "val_datapipe = val_datapipe.limit(int(1e3)).batch(100).collate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining and applying batch data transformation function\n",
    "\n",
    "At this point, each item that is read from `train_datapipe` and `val_datapipe` is a dictionary representing a batch of 100 Criteo Terabyte samples (\"batch dictionary\"). The dictionary maps each string feature name to 100 feature values, each corresponding to a sample in the batch.\n",
    "\n",
    "Each of the 13 feature names corresponding to integer-valued features (\"int_0\" through \"int_12\") maps to a shape-(100,) tensor of integers; each of the 26 feature names corresponding to categorical features (\"cat_0\" through \"cat_25\") maps to a length-100 list of hex strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_0: tensor([  0, 118,   3,  ...,  24,  12,   1])\n",
      "cat_0: ['35b29d1c', '0ede8acc', '9a38fdbd', 'b7590909', 'f7f317e1', 'e5f3fd8d', '74a30cd8', 'a2309537', '0d2de9b7', 'd173a71b', '9bb030cc', 'd080dcdd', 'e5f3fd8d', '75bbaf08', 'fd2294fd', '6f88737d', '7f5629e3', '4ba9ec22', 'b1e51346', 'ae08ee40', '6dfe5365', 'b401509b', '', '288878ba', '', 'e5f3fd8d', '11440f4a', 'e5f3fd8d', '4a3130c4', '6f4012dc', 'a1c393aa', 'a5ba1c3d', '105fc022', 'e5f3fd8d', '', '5deaeb35', '8175c6fa', '265366bf', '', '8a2b1e43', 'ad98e872', 'ad98e872', '36ad0c3a', 'faec4515', 'ad98e872', '372034f9', '788a5d5b', 'e5f3fd8d', '240b1f33', 'ad98e872', 'a6367ddd', '84bff54b', '265366bf', 'cc1858ef', '03fd28c6', 'f6771153', '76d82355', 'ad98e872', '73de94cd', '265366bf', 'ad98e872', 'ad98e872', '32818e9b', '788a5d5b', 'b2d27a4e', '341cc7aa', 'ad98e872', '4d4b357f', '10a8c43d', '6a6402aa', 'ad98e872', '2edf58c3', '', 'ad98e872', 'b2d27a4e', 'b401509b', '2c4bc41a', '7592d348', 'ad98e872', '0d5c791d', 'ad98e872', 'ad98e872', '922980a7', 'ff0adf28', '788a5d5b', 'ad98e872', '5f430440', '', 'ad98e872', 'ad98e872', 'ad98e872', '8a2b1e43', '265366bf', '', '15548013', 'b380001c', 'c250bf94', 'ad98e872', 'ad98e872', '41a99438']\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_datapipe))\n",
    "print(\"int_0:\", batch[\"int_0\"])\n",
    "print(\"cat_0:\", batch[\"cat_0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few data transformations we'd like to apply to each batch dictionary to produce the data we want to feed into our model:\n",
    "- Normalize integer feature values, e.g. by applying a logarithmic function.\n",
    "- Map each categorical feature hex string value to an integer that can be used to index into an embedding table.\n",
    "- Separate integer features, categorical features, and labels into individual tensors reshaped appropriately.\n",
    "\n",
    "Towards accomplishing this, we define a function `_transform` that accepts a batch dictionary as an input, applies the aforementioned transformations, and returns a tuple of three tensors corresponding to integer features, categorical features, and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrec.datasets.criteo import DEFAULT_CAT_NAMES, DEFAULT_INT_NAMES, DEFAULT_LABEL_NAME\n",
    "\n",
    "NUM_EMBEDDINGS = int(1e5)\n",
    "\n",
    "col_transforms = {\n",
    "    **{name: lambda x: torch.log(x + 2) for name in DEFAULT_INT_NAMES},\n",
    "    **{\n",
    "        name: lambda x: x.fmod(NUM_EMBEDDINGS - 1) + 1\n",
    "        for name in DEFAULT_CAT_NAMES\n",
    "    },\n",
    "}\n",
    "    \n",
    "def _transform(\n",
    "    batch: Dict[str, List[Union[int, str]]]\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    int_x = torch.cat(\n",
    "        [\n",
    "            col_transforms[col_name](torch.tensor(batch[col_name]).unsqueeze(0).T)\n",
    "            for col_name in DEFAULT_INT_NAMES\n",
    "            if col_name in col_transforms\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    cat_x = torch.cat(\n",
    "        [\n",
    "            col_transforms[col_name](\n",
    "                torch.tensor([int(v, 16) if v else -1 for v in batch[col_name]])\n",
    "                .unsqueeze(0)\n",
    "                .T\n",
    "            )\n",
    "            for col_name in DEFAULT_CAT_NAMES\n",
    "            if col_name in col_transforms\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    y = torch.tensor(batch[DEFAULT_LABEL_NAME], dtype=torch.float32).unsqueeze(1)\n",
    "    return int_x, cat_x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using `map`, we produce a new pair of train and validation datapipes that applies `_transform` to each batch dictionary of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datapipe = train_datapipe.map(_transform)\n",
    "val_datapipe = val_datapipe.map(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6931, 0.6931, 0.6931,  ..., 0.6931, 1.0986, 0.6931],\n",
       "         [4.7875, 0.6931, 2.5649,  ..., 0.6931, 6.0234, 2.8332],\n",
       "         [1.6094, 5.4638, 2.6391,  ..., 1.7918, 7.9697, 2.6391],\n",
       "         ...,\n",
       "         [3.2581, 7.3343, 1.7918,  ..., 1.7918, 7.8921, 1.7918],\n",
       "         [2.6391, 2.9957, 1.3863,  ..., 1.0986, 8.0064, 1.3863],\n",
       "         [1.0986, 1.0986, 1.0986,  ..., 0.6931, 4.8675, 1.0986]]),\n",
       " tensor([[ 7086, 25811, 76217,  ..., 89288, 33022, 22656],\n",
       "         [68043, 68258, 52745,  ..., 81118, 40776, 34095],\n",
       "         [52112, 50486, 12400,  ...,  6322, 33022, 47765],\n",
       "         ...,\n",
       "         [ 8472, 85233, 86687,  ..., 68498, 33022, 87620],\n",
       "         [ 8472, 94259, 77092,  ..., 77871, 70499, 87620],\n",
       "         [43585, 52600,  2570,  ...,  3211, 51896, 67374]]),\n",
       " tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "bento_obj_id": "140592381608960"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_datapipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got datapipes that produce data that we can train and evaluate a model on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining model\n",
    "To utilize the integer (dense) and categorical (sparse) features present in the Criteo Terabyte dataset, we define `TestSparseNN`, which maps dense and sparse features to embeddings and interacts the embeddings to produce an output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrec.fb.modules.mlp import LazyMLP\n",
    "\n",
    "\n",
    "class TestSparseNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        hidden_layer_size,\n",
    "        output_dim,\n",
    "        sparse_input_size,\n",
    "        num_embeddings,\n",
    "        embedding_dim,\n",
    "    ):\n",
    "        super(TestSparseNN, self).__init__()\n",
    "        self.dense_arch = LazyMLP([hidden_layer_size, embedding_dim])\n",
    "        self.embedding_layers = self._embedding_layers(\n",
    "            sparse_input_size, num_embeddings, embedding_dim\n",
    "        )\n",
    "        self.over_arch = LazyMLP([output_dim])\n",
    "        self.final = torch.nn.LazyLinear(1)\n",
    "\n",
    "    def _embedding_layers(self, sparse_input_size, num_embeddings, embedding_dim):\n",
    "        return torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=0)\n",
    "                for _ in range(sparse_input_size)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _interact(self, embeddings):\n",
    "        batch_size, embedding_dim = embeddings[0].shape\n",
    "        stacked_embeddings = torch.cat(embeddings, dim=1).view(\n",
    "            batch_size, -1, embedding_dim\n",
    "        )\n",
    "        interactions = torch.matmul(\n",
    "            stacked_embeddings, torch.transpose(stacked_embeddings, 1, 2)\n",
    "        )\n",
    "        _, embedding_count, _ = interactions.shape\n",
    "        rows, cols = torch.tril_indices(embedding_count, embedding_count)\n",
    "        return interactions[:, rows, cols]\n",
    "\n",
    "    def forward(self, dense_x, cat_x):\n",
    "        embedded_dense = self.dense_arch(dense_x)\n",
    "        embedded_sparse = [\n",
    "            embedding_layer(cat_x[:, idx])\n",
    "            for idx, embedding_layer in enumerate(self.embedding_layers)\n",
    "        ]\n",
    "        interactions = self._interact([embedded_dense] + embedded_sparse)\n",
    "        return self.final(\n",
    "            self.over_arch(torch.cat([embedded_dense, interactions], dim=1))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and evaluating model\n",
    "We can now train an instance of `TestSparseNN` on data supplied by `train_datapipe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.536839  0\n",
      "loss: 0.127229  100\n",
      "loss: 0.322483  200\n",
      "loss: 0.155279  300\n",
      "loss: 0.143317  400\n",
      "loss: 0.244847  500\n",
      "loss: 0.264295  600\n",
      "loss: 0.136220  700\n",
      "loss: 0.040959  800\n",
      "loss: 0.080234  900\n"
     ]
    }
   ],
   "source": [
    "model = TestSparseNN(\n",
    "    hidden_layer_size=20,\n",
    "    output_dim=10,\n",
    "    sparse_input_size=26,\n",
    "    num_embeddings=NUM_EMBEDDINGS,\n",
    "    embedding_dim=16,\n",
    ")\n",
    "\n",
    "# Initialize lazy modules.\n",
    "int_x, cat_x, y = next(iter(train_datapipe))\n",
    "model(int_x, cat_x)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "for batch_num, (int_x, cat_x, y) in enumerate(train_datapipe):\n",
    "    res = model(int_x, cat_x)\n",
    "    loss = loss_fn(res, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch_num % 1 == 0:\n",
    "        loss, current = loss.item(), batch_num * len(y)\n",
    "        print(f\"loss: {loss:>7f}  {current}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", and evaluate the trained model on data supplied by `val_datapipe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "AUROC: 0.530097 Avg loss: 0.126038\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for int_x, cat_x, y in val_datapipe:\n",
    "        pred = model(int_x, cat_x)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(y)\n",
    "\n",
    "auroc = sklearn.metrics.roc_auc_score(\n",
    "    torch.cat(y_true).view(-1),\n",
    "    torch.sigmoid(torch.cat(y_pred).view(-1)),\n",
    ")\n",
    "val_loss = loss_fn(\n",
    "    torch.cat(y_pred).view(-1),\n",
    "    torch.cat(y_true).view(-1),\n",
    ")\n",
    "\n",
    "print(\"Test results:\")\n",
    "print(f\"AUROC: {auroc:>8f} Avg loss: {val_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and evaluating model on GPU\n",
    "\n",
    "If we have access to a GPU device, we can leverage it as follows to accelerate model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.120394  0\n",
      "loss: 0.122464  10000\n",
      "loss: 0.148007  20000\n",
      "loss: 0.153441  30000\n",
      "loss: 0.124577  40000\n",
      "loss: 0.146918  50000\n",
      "loss: 0.153290  60000\n",
      "loss: 0.124814  70000\n",
      "loss: 0.139988  80000\n",
      "loss: 0.155026  90000\n",
      "loss: 0.127663  100000\n",
      "loss: 0.128998  110000\n",
      "loss: 0.149047  120000\n",
      "loss: 0.130756  130000\n",
      "loss: 0.098698  140000\n",
      "loss: 0.156221  150000\n",
      "loss: 0.144935  160000\n",
      "loss: 0.111010  170000\n",
      "loss: 0.165140  180000\n",
      "loss: 0.162504  190000\n",
      "loss: 0.126021  200000\n",
      "loss: 0.133386  210000\n",
      "loss: 0.146822  220000\n",
      "loss: 0.139569  230000\n",
      "loss: 0.134351  240000\n",
      "loss: 0.143748  250000\n",
      "loss: 0.127452  260000\n",
      "loss: 0.150848  270000\n",
      "loss: 0.110147  280000\n",
      "loss: 0.121761  290000\n",
      "loss: 0.148827  300000\n",
      "loss: 0.135799  310000\n",
      "loss: 0.143518  320000\n",
      "loss: 0.147040  330000\n",
      "loss: 0.147874  340000\n",
      "loss: 0.158020  350000\n",
      "loss: 0.117170  360000\n",
      "loss: 0.160049  370000\n",
      "loss: 0.124524  380000\n",
      "loss: 0.147427  390000\n",
      "loss: 0.143686  400000\n",
      "loss: 0.145967  410000\n",
      "loss: 0.140429  420000\n",
      "loss: 0.129113  430000\n",
      "loss: 0.136281  440000\n",
      "loss: 0.163455  450000\n",
      "loss: 0.102815  460000\n",
      "loss: 0.126294  470000\n",
      "loss: 0.152309  480000\n",
      "loss: 0.130393  490000\n",
      "loss: 0.151293  500000\n",
      "loss: 0.140869  510000\n",
      "loss: 0.156620  520000\n",
      "loss: 0.151464  530000\n",
      "loss: 0.146070  540000\n",
      "loss: 0.153463  550000\n",
      "loss: 0.142922  560000\n",
      "loss: 0.152070  570000\n",
      "loss: 0.123993  580000\n",
      "loss: 0.166800  590000\n",
      "loss: 0.126718  600000\n",
      "loss: 0.187246  610000\n",
      "loss: 0.139779  620000\n",
      "loss: 0.132810  630000\n",
      "loss: 0.149490  640000\n",
      "loss: 0.125739  650000\n",
      "loss: 0.156822  660000\n",
      "loss: 0.137232  670000\n",
      "loss: 0.146410  680000\n",
      "loss: 0.122474  690000\n",
      "loss: 0.116913  700000\n",
      "loss: 0.133779  710000\n",
      "loss: 0.150961  720000\n",
      "loss: 0.121909  730000\n",
      "loss: 0.130351  740000\n",
      "loss: 0.137554  750000\n",
      "loss: 0.139059  760000\n",
      "loss: 0.116831  770000\n",
      "loss: 0.139617  780000\n",
      "loss: 0.150021  790000\n",
      "loss: 0.155689  800000\n",
      "loss: 0.140969  810000\n",
      "loss: 0.122985  820000\n",
      "loss: 0.145107  830000\n",
      "loss: 0.146708  840000\n",
      "loss: 0.113037  850000\n",
      "loss: 0.081020  860000\n",
      "loss: 0.139679  870000\n",
      "loss: 0.151576  880000\n",
      "loss: 0.125169  890000\n",
      "loss: 0.148480  900000\n",
      "loss: 0.154493  910000\n",
      "loss: 0.148526  920000\n",
      "loss: 0.141710  930000\n",
      "loss: 0.138688  940000\n",
      "loss: 0.166732  950000\n",
      "loss: 0.146822  960000\n",
      "loss: 0.140306  970000\n",
      "loss: 0.161611  980000\n",
      "loss: 0.149240  990000\n",
      "Test results:\n",
      "AUROC: 0.724610 Avg loss: 0.131163\n"
     ]
    }
   ],
   "source": [
    "assert(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "datapipe = criteo_terabyte(\n",
    "    (\"/home/jeffhwang/local/datasets/criteo/day_11.tsv\",),\n",
    ")\n",
    "train_datapipe, val_datapipe = idx_split_train_val(datapipe, 70)\n",
    "train_datapipe = train_datapipe.limit(int(1e6)).batch(1000).collate().map(_transform)\n",
    "val_datapipe = val_datapipe.limit(int(1e5)).batch(1000).collate().map(_transform)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "int_x, cat_x, y = next(iter(train_datapipe))\n",
    "int_x, cat_x, y = int_x.to(device), cat_x.to(device), y.to(device)\n",
    "model(int_x, cat_x)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-2, weight_decay=1e-6)\n",
    "\n",
    "for batch_num, (int_x, cat_x, y) in enumerate(train_datapipe):\n",
    "    int_x, cat_x, y = int_x.to(device), cat_x.to(device), y.to(device)\n",
    "    res = model(int_x, cat_x)\n",
    "    loss = loss_fn(res, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_num % 10 == 0:\n",
    "        loss, current = loss.item(), batch_num * len(y)\n",
    "        print(f\"loss: {loss:>7f}  {current}\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for int_x, cat_x, y in val_datapipe:\n",
    "        int_x, cat_x, y = int_x.to(device), cat_x.to(device), y.to(device)\n",
    "        pred = model(int_x, cat_x)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(y)\n",
    "\n",
    "auroc = sklearn.metrics.roc_auc_score(\n",
    "    torch.cat(y_true).view(-1).cpu(),\n",
    "    torch.sigmoid(torch.cat(y_pred).view(-1)).cpu(),\n",
    ")\n",
    "val_loss = loss_fn(\n",
    "    torch.cat(y_pred).view(-1).cpu(),\n",
    "    torch.cat(y_true).view(-1).cpu(),\n",
    ")\n",
    "\n",
    "print(\"Test results:\")\n",
    "print(f\"AUROC: {auroc:>8f} Avg loss: {val_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anp_metadata": {
   "path": "notebooks/fbsource/fbcode/torchrec/examples/criteo_tutorial.ipynb"
  },
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "disseminate_notebook_id": {
   "notebook_id": "515185369527336"
  },
  "disseminate_notebook_info": {
   "backup_notebook_id": "472451483979616",
   "bento_version": "20210606-210329",
   "description": "",
   "hide_code": false,
   "hipster_group": "",
   "kernel_build_info": {
    "deps": [
     "//caffe2/caffe2/fb/ifbpy:all_pytorch_and_caffe2_deps",
     "//github/third-party/PyTorchLightning/pytorch-lightning:lib"
    ],
    "external_deps": []
   },
   "no_uii": true,
   "notebook_number": "770927",
   "others_can_edit": false,
   "reviewers": "",
   "revision_id": "483679666198664",
   "tags": "",
   "tasks": "",
   "title": "criteo_tutorial"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "bento_kernel_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
